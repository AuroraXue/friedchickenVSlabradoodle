kernel= "radial", cost = seq(0.005,0.1,0.01), gamma =c(0.5,1,2) ,scale=F)
svm_linear$best.parameters
svm_radial$best.parameters
pred_linear <- predict(svm_linear$best.model, testset[,-257])
pred_radial <- predict(svm_radial$best.model, testset[,-257])
error_linear <- sum(testset$y != pred_linear)/nrow(testset)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear")
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_linear$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Linear")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,1,0.05),scale=F)
library(e1071)
train5 <- read.csv("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_3/train.5.txt",
sep = ",",header = F)
train6 <- read.csv("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_3/train.6.txt",
sep = ",",header = F)
train5$y <- factor(rep("1", nrow(train5)))
train6$y <- factor(rep("-1", nrow(train6)))
bind <- rbind(train5,train6)
bind$y <- bind$y
index <- 1:nrow(bind)
testindex <- sample(index, length(index)*0.2)
testset <- bind[testindex,]
trainset <- bind[-testindex,]
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,1,0.05),scale=F)
seq(0.005,1,0.05
)
seq(0.005,0.1,0.01)
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,0.1,0.01),scale=F)
pred_linear <- predict(svm_linear$best.model, testset[,-257])
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear")
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = seq(0.005,0.1,0.01), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
pred_linear <- predict(svm_linear$best.model, testset[,-257])
pred_radial <- predict(svm_radial$best.model, testset[,-257])
error_linear <- sum(testset$y != pred_linear)/nrow(testset)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
heatmap(data.matrix(svm_linear$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Linear")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_linear
svm_linear$best.parameters
error_radial
svm_kernel$best.parameters
error_radial
svm_radial$best.parameters
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.001,0.05,0.01),scale=F)
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear", type = "b")
svm_linear$best.parameters
seq(0.001,0.01,0.005)
seq(0.001,0.01,0.002)
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = seq(0.001,0.01,0.002), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = 10^c(-1:2), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = 10^c(-1:2), gamma =c(0.5,5,10) ,scale=F)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
kernel <- ker[1]
ker <- c("linear", "radial")
kernel <- ker[1]
kernel
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
sift <- read.csv("../project 3/training_data/sift_features/sift_features.csv")
sift <- t(sift)
label <- read.csv("../Project 3/training_data/labels.csv")
label$V1 <- as.numeric(label$V1)
sift <- data.frame(cbind(label,sift))
##creat train and test data
set.seed(100)
index <- 1:nrow(sift)
test.index <- sample(index, length(index)*0.2)
train <- sift[-test.index,]
test <- sift[test.index,]
img_dir <- "../training_dat/"
train_dir <- paste(img_dir, "train/", sep = "")
test_dir <- paste(img_dir, "test/", sep = "")
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear"
scale = F)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(training_data = train, cost = 10, K = 5)
cv.function(train[,-1], train[,1] cost = 10, K = 5)
cv.function(train[,-1], train[,1] c = 10, K = 5)
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
set.seed(100)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
10^c(-1:2)
cv.function(train[,-1], train[,1] ,c = 0.1, K = 5)
cv.function(train[,-1], train[,1], c = 1, K = 5)
cv.function(train[,-1], train[,1], c = 10, K = 5)
cv.function(train[,-1], train[,1], c = 100, K = 5)
cv <- NULL
cv[1,] <- c(1,2)
cv[1,] <- 1,2
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
matr <- NULL
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
matr[i,1] <- mean(cv.error)
matr[i,2] <- sd(cv.error)
return(matr)
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
matr <- NULL
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
matr[i,1] <- mean(cv.error)
matr[i,2] <- sd(cv.error)
return(matr)
}
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
mat <- NULL
mat[1,1] <- 2
?matrix
mat[1,1] <- as.numeric(2)
mat(NA, 2,3)
mat <- matrix(NA, 2,3)
mat
mat[1,1] <- 2
mat <- data.frame(NA)
mat
mat[1,1] <- 2
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
return(error)
}
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
?data.frame
error <- data.frame(NA, colnames = c("error.mean", "error.sd"))
error
?colnames
error <- data.frame(NA)
colnames(error) <- c("error.mean", "error.sd")
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(error)
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
cv.function(train[,-1], train[,1] ,c = c(100,200,1000), K = 5)
mat <- (NA,3,3)
mat <- data.frame(NA,3,3)
mat
data.frame()
?data.frame
mat <- matrix(NA, 3,3)
d.f <- data.frame(mat)
d.f
cbind(c(1:3), d.f)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(list(error.df = cbind(cost,error), best_cost = error.df[which.min(error.df[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
cost <- c
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(list(error.df = cbind(cost,error), best_cost = error.df[which.min(error.df[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
cost <- c
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- c[i]
error[i,2] <- mean(cv.error)
error[i,3] <- sd(cv.error)
}
return(list( error, best_cost = error[which.min(error[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.result
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3), K = 5)
cv.result
best_svm <- svm(train[,1], as.factor(train[,-1]), data = train,
cost = cv.result$best_cost,
scale = F)
cv.result$best_cost
best_svm <- svm(train[,-1], as.factor(train[,1]), data = train,
cost = cv.result$best_cost,
scale = F)
pred.test <- predict(best_svm, test[,-1])
pred.error <- mean(pred.test != test[,1])
pred.error
pca <- princomp(train[,1])
pca
pca$scores[,1:2]
pca$scores[,1]
pca <- princomp(train[,1])
two_pca <- cbind(train[,1], pca$scores[,1:2])
head(pca$scores)
pca <- princomp(train[,-1])
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10, 10^2,10^3), K = 10)
cv.result
cv.result
best_svm <- svm(train[,-1], as.factor(train[,1]), data = train,
cost = cv.result$best_cost,
scale = F)
pred.test <- predict(best_svm, test[,-1])
pred.error <- mean(pred.test != test[,1])
pred.error
sample(rep(1:5, c(rep(5, 4), 20-(5-1)*5)))
n <- length(train[,1])
n
n.fold <- floor(1600/5)
n.fold
K <- 5
sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
sift <- read.csv("../spr2017-proj3-group3/training_data/sift_features/sift_features.csv")
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
sift <- read.csv("../project 3/training_data/sift_features/sift_features.csv")
sift <- t(sift)
label <- read.csv("../Project 3/training_data/labels.csv")
label$V1 <- as.numeric(label$V1)
sift <- data.frame(cbind(label,sift))
##creat train and test data
set.seed(100)
index <- 1:nrow(sift)
test.index <- sample(index, length(index)*0.2)
train <- sift[-test.index,]
test <- sift[test.index,]
img_dir <- "../training_dat/"
train_dir <- paste(img_dir, "train/", sep = "")
test_dir <- paste(img_dir, "test/", sep = "")
train <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
train <- sift[-test.index,]
train.fn <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
train.fn(train[,-1], train[,1], c = 100)
test.fn <- function( data_test, cost = 10){
fit_train <- train.fn(train[,-1], train[,1], c = cost)
pred <- predict(fit_train$fit, data_test[,-1])
pred.er <- mean(pred != data_test[,1])
return(pred.er)
}
test.fn(test, cost = 10)
train.fn(train[,-1], train[,1],c = 10)
fit_train <- train.fn(train[,-1], train[,1],c = 10)
test.fn <- function( data_test, cost = 10){
fit_train <- train.fn(train[,-1], train[,1], c = cost)
pred <- predict(fit_train, data_test[,-1])
pred.er <- mean(pred != data_test[,1])
return(pred.er)
}
test.fn(test, cost = 10)
