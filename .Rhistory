<<<<<<< HEAD
kernel= "radial", cost = seq(0.005,0.1,0.01), gamma =c(0.5,1,2) ,scale=F)
svm_linear$best.parameters
svm_radial$best.parameters
pred_linear <- predict(svm_linear$best.model, testset[,-257])
pred_radial <- predict(svm_radial$best.model, testset[,-257])
error_linear <- sum(testset$y != pred_linear)/nrow(testset)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear")
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_linear$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Linear")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,1,0.05),scale=F)
library(e1071)
train5 <- read.csv("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_3/train.5.txt",
sep = ",",header = F)
train6 <- read.csv("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_3/train.6.txt",
sep = ",",header = F)
train5$y <- factor(rep("1", nrow(train5)))
train6$y <- factor(rep("-1", nrow(train6)))
bind <- rbind(train5,train6)
bind$y <- bind$y
index <- 1:nrow(bind)
testindex <- sample(index, length(index)*0.2)
testset <- bind[testindex,]
trainset <- bind[-testindex,]
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,1,0.05),scale=F)
seq(0.005,1,0.05
)
seq(0.005,0.1,0.01)
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.005,0.1,0.01),scale=F)
pred_linear <- predict(svm_linear$best.model, testset[,-257])
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear")
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = seq(0.005,0.1,0.01), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
pred_linear <- predict(svm_linear$best.model, testset[,-257])
pred_radial <- predict(svm_radial$best.model, testset[,-257])
error_linear <- sum(testset$y != pred_linear)/nrow(testset)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
heatmap(data.matrix(svm_linear$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Linear")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_linear
svm_linear$best.parameters
error_radial
svm_kernel$best.parameters
error_radial
svm_radial$best.parameters
svm_linear <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "linear", cost = seq(0.001,0.05,0.01),scale=F)
plot(svm_linear$performances[,2], svm_linear$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Linear", type = "b")
svm_linear$best.parameters
seq(0.001,0.01,0.005)
seq(0.001,0.01,0.002)
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = seq(0.001,0.01,0.002), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = 10^c(-1:2), gamma =c(0.5,1,2) ,scale=F)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
svm_radial <- tune.svm(x = trainset[,-257], y = trainset$y, data = trainset,
kernel= "radial", cost = 10^c(-1:2), gamma =c(0.5,5,10) ,scale=F)
error_radial <- sum(testset$y != pred_radial)/nrow(testset)
plot(svm_radial$performances[,2], svm_radial$performances[,3],
xlab = "Cost", ylab = "Misclassification Rate", main = "SVM Radial")
heatmap(data.matrix(svm_radial$performances[,-4]), Colv = NA, Rowv = NA,
col = heat.colors(256),scale = "column", margins = c(5,10), main = "SVM Radial")
error_radial
kernel <- ker[1]
ker <- c("linear", "radial")
kernel <- ker[1]
kernel
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
sift <- read.csv("../project 3/training_data/sift_features/sift_features.csv")
sift <- t(sift)
label <- read.csv("../Project 3/training_data/labels.csv")
label$V1 <- as.numeric(label$V1)
sift <- data.frame(cbind(label,sift))
##creat train and test data
set.seed(100)
index <- 1:nrow(sift)
test.index <- sample(index, length(index)*0.2)
train <- sift[-test.index,]
test <- sift[test.index,]
img_dir <- "../training_dat/"
train_dir <- paste(img_dir, "train/", sep = "")
test_dir <- paste(img_dir, "test/", sep = "")
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear"
scale = F)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
=======
library(tidyr)
library(ggplot2)
carOffers <- data.frame(Young=c(23,25,21,22,21,22,20,23,19,22,19,21),Middle=c(28,27,27,29,26,29,27,30,28,27,26,22),Elderly=c(23,20,25,21,22,23,21,20,19,20,22,21))
carOffers <- carOffers%>%gather(age, price, Young:Elderly)
carOffers$age <- as.factor(carOffers$age)
ggplot()+geom_boxplot(carOffers,aes(factor(age),price))
library(dplyr)
library(tidyr)
library(ggplot2)
carOffers <- data.frame(Young=c(23,25,21,22,21,22,20,23,19,22,19,21),Middle=c(28,27,27,29,26,29,27,30,28,27,26,22),Elderly=c(23,20,25,21,22,23,21,20,19,20,22,21))
carOffers <- carOffers%>%gather(age, price, Young:Elderly)
carOffers$age <- as.factor(carOffers$age)
ggplot()+geom_boxplot(data=carOffers,aes(factor(age),price))
qqplot(carOffers$price)
pplot(carOffers$price)
qqnorm(carOffers$price)
qqline
qqnorm(carOffers$price)
qqline()
qqnorm(carOffers$price)
qqline(carOffers$price)
par(mfrow=c(1,3))
qqnorm(carOffers$price)
qqline(carOffers$price)
qqnorm(carOffers$price)
qqline(carOffers$price)
qqnorm(carOffers$price)
qqline(carOffers$price)
par(mfrow=c(1,3))
title('All Groups')
par(mfrow=c(1,3))
qqnorm(carOffers$price)
qqline(carOffers$price)
title('All Groups')
qqnorm(carOffers$price)
qqline(carOffers$price)
qqnorm(carOffers$price)
qqline(carOffers$price)
par(mfrow=c(1,3))
qqnorm(carOffers$price,title('All Groups'))
par(mfrow=c(1,3))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
qqnorm(carOffers$price)
qqline(carOffers$price)
qqnorm(carOffers$price)
qqline(carOffers$price)
par(mfrow=c(1,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
qqnorm(carOffers%>%filter(age==as.factor("Young"))%>%select(price))
par(mfrow=c(1,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
qqnorm(carOffers%>%filter(age=="Young")%>%select(price))
carOffers%>%filter(age=="Young")%>%select(price)
par(mfrow=c(1,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
qqnorm(carOffers%>%filter(age=="Young")%>%select(price)$price)
par(mfrow=c(1,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
y1 <- carOffers%>%filter(age=="Young")%>%select(price)
qqnorm(y1$price)
qqline(y1$price)
par(mfrow=c(2,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
y1 <- carOffers%>%filter(age=="Young")%>%select(price)
qqnorm(y1$price,main="Normal Q-Q Plot for Young Age Group")
qqline(y1$price)
y2 <- carOffers%>%filter(age=="Middle")%>%select(price)
qqnorm(y2$price,main="Normal Q-Q Plot for Middle Age Group")
qqline(y2$price)
y3 <- carOffers%>%filter(age=="Elderly")%>%select(price)
qqnorm(y3$price,main="Normal Q-Q Plot for Elderly Age Group")
qqline(y3$price)
par(mfrow=c(2,2))
qqnorm(carOffers$price,main="Normal Q-Q Plot for all Groups")
qqline(carOffers$price)
y1 <- carOffers%>%filter(age=="Young")%>%select(price)
qqnorm(y1$price,main="Normal Q-Q Plot for Young Age Group")
qqline(y1$price)
y2 <- carOffers%>%filter(age=="Middle")%>%select(price)
qqnorm(y2$price,main="Normal Q-Q Plot for Middle Age Group")
qqline(y2$price)
y3 <- carOffers%>%filter(age=="Elderly")%>%select(price)
qqnorm(y3$price,main="Normal Q-Q Plot for Elderly Age Group")
qqline(y3$price)
pairwise.t.test(carOffers$age,carOffers$price,pool.sd = TRUE,p.adjust.method = "bonf")
pairwise.t.test(carOffers$price,carOffers$age, pool.sd = TRUE,p.adjust.method = "bonf")
pairwise.t.test(carOffers$price,carOffers$age, pool.sd = TRUE,p.adjust.method = "bonf")
fit <- aov(carOffers$price~carOffers$age)
TukeyHSD(fit)
x = 0:0.01:1
x
x = seq(0,1,100)
x
x = seq(0,1,length=100)
length(x)
x
y = x^20
plot(x,y)
pt(1)
pt(1,19)
2*(1-pt(1,19))
install.packages("cowplot")
install.packages("cowplot")
install.packages("cowplot", repos="http://cran.r-project.org/")
devtools::install_github("wilkelab/cowplot")
updateR
updateR()
install.packages("installr")
require(devtools)
install_github('andreacirilloac/updateR')
updateR()
updateR::updateR()
updateR::updateR(admin_password = 'reinhard970907')
updateR::updateR(admin_password = 'reinhard970907')
R.version()
R.version
R.version
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
library(shiny)
mh2009=read.csv(file="../data/ManhattanHousing.csv")
datatable(sample_n(mh2009, 50))
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
count.df=mh2009%>%
group_by(region)%>%
summarise(
value=n()
)
save(count.df, file="../output/count.RData")
if (!require("choroplethr")) install.packages("choroplethr")
if (!require("devtools")) install.packages("devtools")
library(devtools)
if (!require("choroplethrZip"))
devtools::install_github('arilamstein/choroplethrZip@v1.5.0')
if (!require("ggplot2")) devtools::install_github("hadley/ggplot2")
if (!require("ggmap")) devtools::install_github("dkahle/ggmap")
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
library(ggmap)
library(dplyr)
mh2009.selgeo=
mh2009%>%
sample_n(10)%>%
select(starts_with("ADD"))%>%
mutate(ADDRESS_Ext=paste(ADDRESS, "New York, NY", sep=","))%>%
mutate_geocode(ADDRESS_Ext)
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
if (!require("ggplot2")) devtools::install_github("hadley/ggplot2")
if (!require("ggmap")) devtools::install_github("dkahle/ggmap")
library(ggmap)
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(devtools)
install_version("ggplot2", version = "2.1.0", repos = "http://cran.us.r-project.org")
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
shiny::runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Project2_OpenData/app')
install.packages('leaflet')
runApp('Documents/Spring2017/GR5243/MyPrjs/Project2_OpenData/app')
install.packages('rgdal')
runApp('Documents/Spring2017/GR5243/MyPrjs/Project2_OpenData/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Project2_OpenData/app')
f.likelihood <- function(n,y,pi){
l <- choose(n,y)*pi^y*(1-pi)^(n-y)
return(l)
}
p <- seq(0,1,by=0.01)
l <- f.likelihood(20,10,p)
plot(pi,l)
l
pi
p
plot(p,l)
plot(p,l)
l <- f.likelihood(20,19,p)
plot(p,l)
l <- f.likelihood(20,18,p)
plot(p,l)
l <- f.likelihood(20,20,p)
plot(p,l)
qchisq(0.95,1)
1-pchisq(20,1)
3.84/20
1-0.192
1/1.192
1/0.808
log(0.5)*(-40)
1-pchisq(7.7,1)
23.84*(-0.5)
23.84*(-0.5)/20
exp(-0.596)
exp(-1.92/20)
exp(log(0.05)/20)
lamb <- seq(-5,5,by=0.01)
lamb <- seq(0.0001,5,by=0.01)
plot(lamb,log(lamb))
plot(lamb,log(lamb),type = "l",col="green")
lines(lamb,lamb+0.95,col="red")
lamb <- seq(0.0001,30,by=0.01)
plot(lamb,log(lamb),type = "l",col="green")
lines(lamb,lamb+0.95,col="red")
shiny::runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
shiny::runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
library(plyr)
runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
shiny::runApp('Documents/Spring2017/GR5243/MyPrjs/Spr2017-proj2-grp12/app')
152*log(0.6611)+70*log(0.152)-152*log(0.6609)-33*log(0.1435)-37*log(0.1609)
(152*log(0.6611)+70*log(0.152)-152*log(0.6609)-33*log(0.1435)-37*log(0.1609))*(-2)
pchisq(0.32,1)
1-pchisq(0.32,1)
1-pchisq(0.32,2)
mu.a <- 5
mu.b <- 9
mu <- 7
a <- c(8,7,6,6,3,4,7,2,3,4)
b <- c(9,9,8,14,8,13,11,5,7,6)
mean(a)
mean(b)
mean(c(a,b))
exp(-mu.a)*a^mu.a
prod(exp(-mu.a)*a^mu.a)
prod(exp(-mu.a)*a^mu.a)/prod(exp(-mu)*c(a,b)^mu)*prod(exp(-mu.b)*b^mu.b)
l = prod(exp(-mu.a)*a^mu.a)/prod(exp(-mu)*c(a,b)^mu)*prod(exp(-mu.b)*b^mu.b)
-2*log(l)
prod(exp(-mu.b)*b^mu.b)
prod(exp(-mu.b)*(b^mu.b))
sum(-mu.a+mu.a*log(a))
sum(-mu.a+mu.a*log(a))+sum(-mu.b+mu.b*log(b))
sum(-mu+mu*log(c(a,b)))
c(a,b)
log(c(a,b))
log(c(a,b))*mu
log(c(a,b))*mu-mu
sum(log(c(a,b))*mu-mu)
sum(-mu.b+mu.b*log(b))
sum(-mu.a+mu.a*log(a))+sum(-mu.b+mu.b*log(b))-sum(-mu+mu*log(c(a,b)))
sum(-mu.a+mu.a*log(a))+sum(-mu.b+mu.b*log(b))-sum(-mu+mu*log(c(a,b)))*2
matrix(c(1,2,3,4),2,2)
matrix(c(140,90,90,90),2,2)
J <- matrix(c(140,90,90,90),2,2)
J
solve(J)
pt(3.3324,1)
pchisq(25.1384,1)
pnorm(3.3324)
log(1.8)-1.96*sqrt(0.03111111)
log(1.8)+1.96*sqrt(0.03111111)
exp(0.2420752)
exp(0.9334982)
wafer.imperf <- data.frame(imperfection=c(8,7,6,6,3,4,7,2,3,4,9,9,8,14,8,13,11,5,7,6),is.B=c(rep(0,10),rep(1,10)))
wafer.imperf
wafer.imperf <- data.frame(imperfection=c(8,7,6,6,3,4,7,2,3,4,9,9,8,14,8,13,11,5,7,6),is.B=factor(c(rep(0,10),rep(1,10))))
wafer.imperf
fit <- glm(imperfection~is.B,data = wafer.imperf,family=binomial(link='logit'))
fit <- glm(imperfection~is.B,data = wafer.imperf,family=poisson(link='log'))
summary(fit)
log(1.8)
fit$coefficients
fit$coefficients[2]
fit$coefficients[[2]]
exp(fit$coefficients[[2]])
exp(fit$coefficients[[2]]) - mean(wafer.imperf$imperfection[11:20])/mean(wafer.imperf$imperfection[1:10])
fit0 <- glm(imperfection~1,data = wafer.imperf,family = poisson(link = 'log'))
summary(fit0)
anova(fit0,fit)
pchisq(11.589,1)
3.332*3.332
fit$effects
fit$coefficients
fit$residuals
fit$fitted.values
fit$R
fit$rank
fit$qr
fit$terms
confint(fit)
exp(confint(fit))
prod(exp(-mu)*c(a,b)^mu)/(prod(exp(-mu.b)*b^mu.b)*prod(exp(-mu.a)*a^mu.a))
log(prod(exp(-mu)*c(a,b)^mu)/(prod(exp(-mu.b)*b^mu.b)*prod(exp(-mu.a)*a^mu.a)))
-2*log(prod(exp(-mu)*c(a,b)^mu)/(prod(exp(-mu.b)*b^mu.b)*prod(exp(-mu.a)*a^mu.a)))
3.3324^2
0.5^20/((5/14)^10*(9/14)^10)
prod(0.5^(a+b))
prod(0.5^(a+b))/(prod((5/14)^a)*prod((9/14)^b))
-2*log(prod(0.5^(a+b))/(prod((5/14)^a)*prod((9/14)^b)))
setwd('/Users/Zoe/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/lib/')
library(dplyr)
library(data.table)
baseline_features <- '../data/sift_features.csv'
advance_features <- '../data/cnn_features_150.csv'
bl_df <- fread(baseline_features,stringsAsFactors = FALSE)
adv_df <- fread(advance_features, stringsAsFactors = FALSE)
labels <- fread('../data/labels.csv')
bl_df <- t(bl_df)
bl_df <- data.frame(bl_df)
bl_df$label <- factor(labels$V1)
bl_df$image <- rownames(bl_df)
adv_df <- t(adv_df)
adv_df <- data.frame(adv_df)
adv_df$label <- factor(labels$V1)
adv_df$image <- rownames(adv_df)
test_imgs <- fread('../output/prediction_inceptionV3.csv')
test_imgs <- test_imgs$image
bl_test <- bl_df[rownames(bl_df)%in%test_imgs,]
bl_train <- bl_df[!(rownames(bl_df)%in%test_imgs),]
rownames(bl_df)
rownames(adv_df)
rownames(adv_df)[1]
strsplit(rownames(adv_df)[1],'.')
strsplit(rownames(adv_df)[1],'\.')
rownames(adv_df)[1][1:-4]
'daa'
'daa'[1]
strsplit(rownames(adv_df)[1],'\\.')
strsplit(rownames(adv_df)[1],'\\.')[1]
strsplit(rownames(adv_df)[1],'\\.')[1][1]
substring('abssss',1,3)
substring('abssss',1,-1)
substring('abssss',-2,-1)
install.packages("stringi")
library(stringi)
stri_sub('acvdvfv',1,-2)
stri_sub('acvdvfv.jpg',1,-5)
test_imgs <- lapply(test_imgs,function(x) stri_sub(x,1,-5))
test_imgs
test_imgs[0]
test_imgs[[0]]
'image_1275' %in% test_imgs
rownames(bl_test)
bl_test
dim(bl_df)
bl_df$image <- lapply(rownames(bl_df),function(x) stri_sub(x,1,-5))
bl_df$image
bl_df
rownames(bl_df)
rownames(adv_df)
labels <- fread('../data/labels.csv')
bl_df <- fread(baseline_features,stringsAsFactors = FALSE)
adv_df <- fread(advance_features, stringsAsFactors = FALSE)
labels <- fread('../data/labels.csv')
bl_df <- t(bl_df)
bl_df <- data.frame(bl_df)
bl_df$label <- factor(labels$V1)
bl_df$image <- rownames(bl_df)
adv_df <- t(adv_df)
adv_df <- data.frame(adv_df)
adv_df$label <- factor(labels$V1)
adv_df$image <- lapply(rownames(adv_df),function(x) stri_sub(x,1,-5))
test_imgs <- fread('../output/prediction_inceptionV3.csv')
test_imgs <- test_imgs$image
test_imgs <- lapply(test_imgs,function(x) stri_sub(x,1,-5))
bl_test <- bl_df[rownames(bl_df)%in%test_imgs,]
bl_train <- bl_df[!(rownames(bl_df)%in%test_imgs),]
head(bl_test)
head(bl_test$label)
head(bl_test$image)
head(bl_test[,1])
adv_test <- adv_df[rownames(adv_df)%in%test_imgs,]
rownames(adv_df)
adv_test <- adv_df[adv_df$image%in%test_imgs,]
adv_train <- adv_df[!(adv_df$image%in%test_imgs),]
bl_save <- '../output/blModel.RData'
adv_save <- '../output/advModel.RData'
X.train <- bl_train[,1:150]
y.train <- bl_train$label
y.train
length(y.train)
d <- 1
K = 5
n <- length(y.train)
n
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
i = 4
>>>>>>> origin/master
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
<<<<<<< HEAD
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(training_data = train, cost = 10, K = 5)
cv.function(train[,-1], train[,1] cost = 10, K = 5)
cv.function(train[,-1], train[,1] c = 10, K = 5)
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
=======
par <- list(depth=d)
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/test.R')
library(gbm)
gbm_fit <- train_bl(bl_train)
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/train_bl.R')
gbm_fit <- train_bl(bl_train)
bl_train$label
trainD <- bl_train
k <- dim(trainD)[1]-1
k
dim(bl_train)
k <- dim(trainD)[2]-1
k
par=NULL
if(is.null(par)){
depth = 1
shrinkage = 0.03
n.trees = 250
}
trainD$label <- as.numeric(trainD$label)
gbm_fit <- gbm(label~ ., data = trainD[,1:k],interaction.depth = depth, n.trees = n.trees, shrinkage = shrinkage)
trainD$label <- as.numeric(trainD$label) - 1
gbm_fit <- gbm(label~ ., data = trainD[,1:k],interaction.depth = depth, n.trees = n.trees, shrinkage = shrinkage)
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/test.R')
preds <- test(gbm_fit,bl_test)
install.packages('xgboost')
preds <- test(gbm_fit,bl_test)
preds
mean(preds!=bl_test$label)
1-mean(preds!=bl_test$label)
train_f <- train_bl()
train_f <- train_bl
train_f
>>>>>>> origin/master
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
<<<<<<< HEAD
for (i in 1:K){
=======
>>>>>>> origin/master
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
<<<<<<< HEAD
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
set.seed(100)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(cost=c)
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = par,
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
cv.function(train[,-1], train[,1] ,c = 10, K = 5)
10^c(-1:2)
cv.function(train[,-1], train[,1] ,c = 0.1, K = 5)
cv.function(train[,-1], train[,1], c = 1, K = 5)
cv.function(train[,-1], train[,1], c = 10, K = 5)
cv.function(train[,-1], train[,1], c = 100, K = 5)
cv <- NULL
cv[1,] <- c(1,2)
cv[1,] <- 1,2
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
matr <- NULL
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
matr[i,1] <- mean(cv.error)
matr[i,2] <- sd(cv.error)
return(matr)
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
matr <- NULL
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
matr[i,1] <- mean(cv.error)
matr[i,2] <- sd(cv.error)
return(matr)
}
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
mat <- NULL
mat[1,1] <- 2
?matrix
mat[1,1] <- as.numeric(2)
mat(NA, 2,3)
mat <- matrix(NA, 2,3)
mat
mat[1,1] <- 2
mat <- data.frame(NA)
mat
mat[1,1] <- 2
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
return(error)
}
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
?data.frame
error <- data.frame(NA, colnames = c("error.mean", "error.sd"))
error
?colnames
error <- data.frame(NA)
colnames(error) <- c("error.mean", "error.sd")
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(error)
}
cv.function(train[,-1], train[,1] ,c = c(100,200), K = 5)
cv.function(train[,-1], train[,1] ,c = c(100,200,1000), K = 5)
mat <- (NA,3,3)
mat <- data.frame(NA,3,3)
mat
data.frame()
?data.frame
mat <- matrix(NA, 3,3)
d.f <- data.frame(mat)
d.f
cbind(c(1:3), d.f)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(list(error.df = cbind(cost,error), best_cost = error.df[which.min(error.df[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
cost <- c
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- mean(cv.error)
error[i,2] <- sd(cv.error)
}
return(list(error.df = cbind(cost,error), best_cost = error.df[which.min(error.df[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.function <- function(X.train, y.train, c, K){
library(e1071)
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
error <- data.frame(NA)
cost <- c
for(i in 1:length(c)){
for (j in 1:K){
train.data <- X.train[s != j,]
train.label <- y.train[s != j]
test.data <- X.train[s == j,]
test.label <- y.train[s == j]
fit <- svm(X.train, as.factor(y.train), data = cbind(X.train, y.train),
cost = c[i],
kernel = "linear",
scale = F)
pred <- predict(fit, test.data)
cv.error[j] <- mean(pred != test.label)
}
error[i,1] <- c[i]
error[i,2] <- mean(cv.error)
error[i,3] <- sd(cv.error)
}
return(list( error, best_cost = error[which.min(error[,2]),1]))
}
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3,10^4), K = 5)
cv.result
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10^2,10^3), K = 5)
cv.result
best_svm <- svm(train[,1], as.factor(train[,-1]), data = train,
cost = cv.result$best_cost,
scale = F)
cv.result$best_cost
best_svm <- svm(train[,-1], as.factor(train[,1]), data = train,
cost = cv.result$best_cost,
scale = F)
pred.test <- predict(best_svm, test[,-1])
pred.error <- mean(pred.test != test[,1])
pred.error
pca <- princomp(train[,1])
pca
pca$scores[,1:2]
pca$scores[,1]
pca <- princomp(train[,1])
two_pca <- cbind(train[,1], pca$scores[,1:2])
head(pca$scores)
pca <- princomp(train[,-1])
cv.result <- cv.function(train[,-1], train[,1] ,c = c(10, 10^2,10^3), K = 10)
cv.result
cv.result
best_svm <- svm(train[,-1], as.factor(train[,1]), data = train,
cost = cv.result$best_cost,
scale = F)
pred.test <- predict(best_svm, test[,-1])
pred.error <- mean(pred.test != test[,1])
pred.error
sample(rep(1:5, c(rep(5, 4), 20-(5-1)*5)))
n <- length(train[,1])
n
n.fold <- floor(1600/5)
n.fold
K <- 5
sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/spr2017-proj3-group3")
sift <- read.csv("../spr2017-proj3-group3/training_data/sift_features/sift_features.csv")
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
setwd("~/Desktop/Columbia/Spring 2017/ADS/Project 3")
sift <- read.csv("../project 3/training_data/sift_features/sift_features.csv")
sift <- t(sift)
label <- read.csv("../Project 3/training_data/labels.csv")
label$V1 <- as.numeric(label$V1)
sift <- data.frame(cbind(label,sift))
##creat train and test data
set.seed(100)
index <- 1:nrow(sift)
test.index <- sample(index, length(index)*0.2)
train <- sift[-test.index,]
test <- sift[test.index,]
img_dir <- "../training_dat/"
train_dir <- paste(img_dir, "train/", sep = "")
test_dir <- paste(img_dir, "test/", sep = "")
train <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
train <- sift[-test.index,]
train.fn <- function(dat_train, label_train, c=10){
library(e1071)
fit_svm <- svm(dat_train, label_train, data = cbind(dat_train,label_train),
cost = c,
kernel = "linear",
scale = F)
return(fit_svm)
}
train.fn(train[,-1], train[,1], c = 100)
test.fn <- function( data_test, cost = 10){
fit_train <- train.fn(train[,-1], train[,1], c = cost)
pred <- predict(fit_train$fit, data_test[,-1])
pred.er <- mean(pred != data_test[,1])
return(pred.er)
}
test.fn(test, cost = 10)
train.fn(train[,-1], train[,1],c = 10)
fit_train <- train.fn(train[,-1], train[,1],c = 10)
test.fn <- function( data_test, cost = 10){
fit_train <- train.fn(train[,-1], train[,1], c = cost)
pred <- predict(fit_train, data_test[,-1])
pred.er <- mean(pred != data_test[,1])
return(pred.er)
}
test.fn(test, cost = 10)
=======
par <- list(depth=d)
fit <- train_f(train.data, train.label, par)
fit <- train_f(train.data, par)
train.data
dim(train.data)
dim(test.data)
g1 <- train_bl(train.data)
trainD <- train.data
k <- dim(trainD)[2]-1
k
dim(X.train)
dim(bl_train)
train_df <- bl_train
n <- dim(train_df)[1]
n
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
train.data <- train_df[s != i,]
train.label <- train_df$label[s != i]
test.data <- train_df[s == i,]
test.label <- train_df$label[s == i]
par <- list(depth=d)
fit <- train_f(train.data, par)
train.data$label
train_f <- train_bl
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/train_bl.R')
train_f <- train_bl
fit <- train_f(train.data, par)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
cv.error[4]
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/lib/cross_validation.R')
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/lib/cross_validation.R')
source('~/Documents/Spring2017/GR5243/MyPrjs/spr2017-proj3-group3/lib/cross_validation.R')
source('./lib/cross_validation.R')
source("./lib/train_bl.R")
source('./lib/cross_validation.R')
setwd('../')
source('./lib/cross_validation.R')
source("./lib/train_bl.R")
seq(100, 300, 50)
n.trees = seq(100, 300, 50)
test_err_BL = numeric(length(shrinkages))
test_err_BL = numeric(length(n.trees))
source('./lib/cross_validation.R')
source("./lib/train_bl.R")
source("./lib/train_adv.R")
n.trees = seq(100, 300, 50)
test_err_BL = numeric(length(n.trees))
j = 1
cat("BL model CV: j =", j, "of",length(n.trees), "\n")
par = list(depth=1,
shrinkage=0.03,
n.trees=n.trees[j])
test_err_BL[j] = cv.f(train_df, par=par, K=5, train_f = train_bl)
test_err_BL[j] = cv.f(train_df, par=par, K=5, train_f = train_bl)
test_err_BL[1]
>>>>>>> origin/master
