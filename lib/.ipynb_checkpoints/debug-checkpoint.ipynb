{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time \n",
    "import random\n",
    "#import sys\n",
    "#import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "#from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train_X, train_y, useTrainCV=True, cv_folds=5, early_stopping_rounds=30):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_X,label=train_y)\n",
    "        #xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        start_train = time()\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='logloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    index = range(train_X.shape[0])\n",
    "    random.shuffle(index)\n",
    "    train_len = int(0.8*train_X.shape[0])\n",
    "    train_index = index[:train_len]\n",
    "    val_index = index[train_len:]\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_X[train_index,:], train_y[train_index,],eval_metric='logloss')\n",
    "    end_train = time()\n",
    "    print('training time: %.4g' % (end_train - start_train))\n",
    "        \n",
    "    #Predict training set:\n",
    "    val_predictions = alg.predict(train_X[val_index,:])\n",
    "    val_predprob = alg.predict_proba(train_X[val_index,:])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy(val) : %.4g\" % accuracy_score(train_y[val_index,], val_predictions)\n",
    "    print \"logloss Score (val): %f\" % log_loss(train_y[val_index,], val_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = xgb1.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76000000000000001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680836</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.656950</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.623260</td>\n",
       "      <td>0.004267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658826</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0.593185</td>\n",
       "      <td>0.006427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646850</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.562975</td>\n",
       "      <td>0.007304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640163</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.537867</td>\n",
       "      <td>0.007488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.632632</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.513151</td>\n",
       "      <td>0.008021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.626698</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>0.492119</td>\n",
       "      <td>0.007942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.619197</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.471745</td>\n",
       "      <td>0.007512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.613525</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.452709</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.609673</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.434061</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.602438</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.416051</td>\n",
       "      <td>0.007936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.598364</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.400393</td>\n",
       "      <td>0.008569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.594523</td>\n",
       "      <td>0.014559</td>\n",
       "      <td>0.385635</td>\n",
       "      <td>0.008190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.591843</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.006520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.587546</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.358028</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.587071</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.345755</td>\n",
       "      <td>0.007046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.583568</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.334133</td>\n",
       "      <td>0.007342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.578998</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.322805</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.576202</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.312214</td>\n",
       "      <td>0.007785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.573887</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.302598</td>\n",
       "      <td>0.007786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.571211</td>\n",
       "      <td>0.017508</td>\n",
       "      <td>0.292458</td>\n",
       "      <td>0.006722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.569087</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.282958</td>\n",
       "      <td>0.005952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.568380</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>0.274453</td>\n",
       "      <td>0.005662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.566636</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.266778</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.564073</td>\n",
       "      <td>0.019268</td>\n",
       "      <td>0.259039</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.562251</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.251079</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.559834</td>\n",
       "      <td>0.021334</td>\n",
       "      <td>0.244201</td>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.557007</td>\n",
       "      <td>0.019873</td>\n",
       "      <td>0.236744</td>\n",
       "      <td>0.004694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.555213</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.229379</td>\n",
       "      <td>0.005742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.554511</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.222260</td>\n",
       "      <td>0.006086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.501851</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.023744</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.501934</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.502065</td>\n",
       "      <td>0.050123</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.501853</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.501420</td>\n",
       "      <td>0.049310</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0.000910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.501616</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>0.022661</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.502062</td>\n",
       "      <td>0.049579</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.502373</td>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.503043</td>\n",
       "      <td>0.050777</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.502705</td>\n",
       "      <td>0.050657</td>\n",
       "      <td>0.021878</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.502397</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.501942</td>\n",
       "      <td>0.051205</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.502334</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.502380</td>\n",
       "      <td>0.051560</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.502321</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.000810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.502080</td>\n",
       "      <td>0.052696</td>\n",
       "      <td>0.020627</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.501624</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.501463</td>\n",
       "      <td>0.052789</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.501126</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.020116</td>\n",
       "      <td>0.000763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.500524</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.500919</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.501040</td>\n",
       "      <td>0.052847</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.500826</td>\n",
       "      <td>0.053275</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.500728</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.054364</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.500637</td>\n",
       "      <td>0.054472</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.500096</td>\n",
       "      <td>0.055061</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.499834</td>\n",
       "      <td>0.055204</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-logloss-mean  test-logloss-std  train-logloss-mean  \\\n",
       "0             0.680836          0.003198            0.656950   \n",
       "1             0.670279          0.005958            0.623260   \n",
       "2             0.658826          0.006989            0.593185   \n",
       "3             0.646850          0.007072            0.562975   \n",
       "4             0.640163          0.009004            0.537867   \n",
       "5             0.632632          0.008216            0.513151   \n",
       "6             0.626698          0.010264            0.492119   \n",
       "7             0.619197          0.010340            0.471745   \n",
       "8             0.613525          0.011675            0.452709   \n",
       "9             0.609673          0.013546            0.434061   \n",
       "10            0.602438          0.014585            0.416051   \n",
       "11            0.598364          0.013450            0.400393   \n",
       "12            0.594523          0.014559            0.385635   \n",
       "13            0.591843          0.014928            0.372093   \n",
       "14            0.587546          0.015434            0.358028   \n",
       "15            0.587071          0.016368            0.345755   \n",
       "16            0.583568          0.015151            0.334133   \n",
       "17            0.578998          0.014366            0.322805   \n",
       "18            0.576202          0.015643            0.312214   \n",
       "19            0.573887          0.016508            0.302598   \n",
       "20            0.571211          0.017508            0.292458   \n",
       "21            0.569087          0.017751            0.282958   \n",
       "22            0.568380          0.017989            0.274453   \n",
       "23            0.566636          0.018361            0.266778   \n",
       "24            0.564073          0.019268            0.259039   \n",
       "25            0.562251          0.019935            0.251079   \n",
       "26            0.559834          0.021334            0.244201   \n",
       "27            0.557007          0.019873            0.236744   \n",
       "28            0.555213          0.022585            0.229379   \n",
       "29            0.554511          0.023191            0.222260   \n",
       "..                 ...               ...                 ...   \n",
       "161           0.501851          0.049113            0.023744   \n",
       "162           0.501934          0.049774            0.023513   \n",
       "163           0.502065          0.050123            0.023305   \n",
       "164           0.501853          0.050022            0.023086   \n",
       "165           0.501420          0.049310            0.022868   \n",
       "166           0.501616          0.049284            0.022661   \n",
       "167           0.502062          0.049579            0.022461   \n",
       "168           0.502373          0.050289            0.022265   \n",
       "169           0.503043          0.050777            0.022065   \n",
       "170           0.502705          0.050657            0.021878   \n",
       "171           0.502397          0.050910            0.021702   \n",
       "172           0.501942          0.051205            0.021523   \n",
       "173           0.502334          0.051599            0.021343   \n",
       "174           0.502380          0.051560            0.021159   \n",
       "175           0.502167          0.052433            0.020978   \n",
       "176           0.502321          0.052501            0.020794   \n",
       "177           0.502080          0.052696            0.020627   \n",
       "178           0.501624          0.052811            0.020454   \n",
       "179           0.501463          0.052789            0.020285   \n",
       "180           0.501126          0.052348            0.020116   \n",
       "181           0.500524          0.052400            0.019952   \n",
       "182           0.500919          0.053083            0.019775   \n",
       "183           0.501040          0.052847            0.019627   \n",
       "184           0.500826          0.053275            0.019469   \n",
       "185           0.500101          0.053463            0.019306   \n",
       "186           0.500728          0.053646            0.019152   \n",
       "187           0.500788          0.054364            0.019000   \n",
       "188           0.500637          0.054472            0.018844   \n",
       "189           0.500096          0.055061            0.018689   \n",
       "190           0.499834          0.055204            0.018557   \n",
       "\n",
       "     train-logloss-std  \n",
       "0             0.002566  \n",
       "1             0.004267  \n",
       "2             0.006427  \n",
       "3             0.007304  \n",
       "4             0.007488  \n",
       "5             0.008021  \n",
       "6             0.007942  \n",
       "7             0.007512  \n",
       "8             0.007847  \n",
       "9             0.007077  \n",
       "10            0.007936  \n",
       "11            0.008569  \n",
       "12            0.008190  \n",
       "13            0.006520  \n",
       "14            0.006578  \n",
       "15            0.007046  \n",
       "16            0.007342  \n",
       "17            0.007813  \n",
       "18            0.007785  \n",
       "19            0.007786  \n",
       "20            0.006722  \n",
       "21            0.005952  \n",
       "22            0.005662  \n",
       "23            0.005442  \n",
       "24            0.005417  \n",
       "25            0.005500  \n",
       "26            0.004473  \n",
       "27            0.004694  \n",
       "28            0.005742  \n",
       "29            0.006086  \n",
       "..                 ...  \n",
       "161           0.000977  \n",
       "162           0.000965  \n",
       "163           0.000938  \n",
       "164           0.000929  \n",
       "165           0.000910  \n",
       "166           0.000892  \n",
       "167           0.000896  \n",
       "168           0.000887  \n",
       "169           0.000875  \n",
       "170           0.000876  \n",
       "171           0.000874  \n",
       "172           0.000859  \n",
       "173           0.000843  \n",
       "174           0.000832  \n",
       "175           0.000819  \n",
       "176           0.000810  \n",
       "177           0.000801  \n",
       "178           0.000787  \n",
       "179           0.000774  \n",
       "180           0.000763  \n",
       "181           0.000750  \n",
       "182           0.000735  \n",
       "183           0.000735  \n",
       "184           0.000717  \n",
       "185           0.000710  \n",
       "186           0.000703  \n",
       "187           0.000690  \n",
       "188           0.000690  \n",
       "189           0.000678  \n",
       "190           0.000674  \n",
       "\n",
       "[191 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.03,\n",
    " n_estimators=400,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " #nthread=4,\n",
    " #scale_pos_weight=1,\n",
    " seed=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 82.85\n",
      "\n",
      "Model Report\n",
      "Accuracy(val) : 0.7438\n",
      "logloss Score (val): 0.526039\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGCCAYAAACvj8rvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111af5350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelfit(xgb1, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 2\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plist = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X,label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test')]\n",
    "        train_start = time()\n",
    "        cvresult = xgb.cv(plist, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='logloss', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        #model = xgb.train(plist,xgtrain,num_rounds,watchlist,early_stopping_rounds=20)\n",
    "        train_end = time()\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        train_start = time()\n",
    "        model = xgb.train(plist, xgtrain, num_rounds)\n",
    "        train_end = time()\n",
    "    \n",
    "    test_start = time()\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    test_end = time()\n",
    "    return pred_test_y, model, (train_end - train_start), (test_end - test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_path = '../../localData/prj3/training_data/sift_features/sift_features_1000.csv'\n",
    "fix_test_path = '../output/prediction_inceptionV3.csv'\n",
    "test_images = pd.read_csv(fix_test_path)['image']\n",
    "test_images = [x.split('.')[0] for x in test_images.tolist()]\n",
    "\n",
    "total_df = pd.read_csv(input_path).transpose()\n",
    "\n",
    "labels = [1 for i in range(1000)] + [0 for i in range(1000)]\n",
    "total_df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for ensemble purpose make sure test set the same as in inceptionV3 model\n",
    "test_df = total_df.ix[total_df.index.isin(test_images)]\n",
    "train_df = total_df.ix[~total_df.index.isin(test_images)]\n",
    "\n",
    "train_X = train_df.ix[:,:1000]\n",
    "train_y = train_df['label']\n",
    "\n",
    "test_X = test_df.ix[:,:1000]\n",
    "test_y = test_df['label']\n",
    "\n",
    "train_X = sparse.csr_matrix(train_X.values)\n",
    "test_X = sparse.csr_matrix(test_X.values)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, _ , training_time, predicting_time = runXGB(train_X, train_y, test_X, num_rounds=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time is:50.34seconds;\n",
      "predicting time is:0.01seconds.\n"
     ]
    }
   ],
   "source": [
    "print('training time is:'+str(round(training_time,2))+'seconds;\\npredicting time is:'+\n",
    "str(round(predicting_time,2))+'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930725</td>\n",
       "      <td>0.069275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.757777</td>\n",
       "      <td>0.242223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.432586</td>\n",
       "      <td>0.567414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802996</td>\n",
       "      <td>0.197004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065175</td>\n",
       "      <td>0.934825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.930725  0.069275\n",
       "1  0.757777  0.242223\n",
       "2  0.432586  0.567414\n",
       "3  0.802996  0.197004\n",
       "4  0.065175  0.934825"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 3\n",
    "param['eval_metric'] = \"mlogloss\"\n",
    "param['min_child_weight'] = 1\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree'] = 0.7\n",
    "param['seed'] = 0\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
